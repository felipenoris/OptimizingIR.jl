var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference-1","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Public-API-1","page":"API Reference","title":"Public API","text":"","category":"section"},{"location":"api/#","page":"API Reference","title":"API Reference","text":"OptimizingIR","category":"page"},{"location":"api/#OptimizingIR","page":"API Reference","title":"OptimizingIR","text":"An  Intermediate Representation (IR) on steroids.\n\n\n\n\n\n","category":"module"},{"location":"api/#Internals-1","page":"API Reference","title":"Internals","text":"","category":"section"},{"location":"api/#","page":"API Reference","title":"API Reference","text":"OptimizingIR.AbstractValue\nOptimizingIR.PureInstruction\nOptimizingIR.ImpureInstruction\nOptimizingIR.compile\nOptimizingIR.SSAValue\nOptimizingIR.try_on_add_instruction_passes\nOptimizingIR.LookupTable\nOptimizingIR.Const\nOptimizingIR.Variable\nOptimizingIR.OptimizationRule","category":"page"},{"location":"api/#OptimizingIR.AbstractValue","page":"API Reference","title":"OptimizingIR.AbstractValue","text":"AbstractValue{M<:Mutability}\n\nA value can be marked as either Mutable or Immutable.\n\nAn immutable value can be assigned only once. A mutable value can be assigned more than once.\n\n\n\n\n\n","category":"type"},{"location":"api/#OptimizingIR.PureInstruction","page":"API Reference","title":"OptimizingIR.PureInstruction","text":"A PureInstruction is a call to an operation that always returns the same value if the same arguments are passed to the instruction. It is suitable for memoization, in the sense that it can be optimized in the Value-Number algorithm inside a Basic Block.\n\n\n\n\n\n","category":"type"},{"location":"api/#OptimizingIR.ImpureInstruction","page":"API Reference","title":"OptimizingIR.ImpureInstruction","text":"An ImpureInstruction is a call to an operation that not always returns the same value if the same arguments are passed to the instruction. It is not suitable for memoization, and the Value-Number optimization must be disabled for this call.\n\nMarking as mutable avoids Value-Numbering for this call.\n\n\n\n\n\n","category":"type"},{"location":"api/#OptimizingIR.compile","page":"API Reference","title":"OptimizingIR.compile","text":"compile(::Type{T}, program::Program) :: Function where {T<:AbstractMachine}\n\n\n\n\n\n","category":"function"},{"location":"api/#OptimizingIR.SSAValue","page":"API Reference","title":"OptimizingIR.SSAValue","text":"A pointer to an instruction that computes a value.\n\n\n\n\n\n","category":"type"},{"location":"api/#OptimizingIR.try_on_add_instruction_passes","page":"API Reference","title":"OptimizingIR.try_on_add_instruction_passes","text":"try_on_add_instruction_passes(program, instruction) :: Union{Nothing, Address}\n\nTries to apply all optimization passes available while running addinstruction!:\n\nfunction addinstruction!(b::BasicBlock, instruction::LinearInstruction) :: Address\n\n    result = try_on_add_instruction_passes(b, instruction)\n    if result != nothing\n        return result\n    end\n\n    # (...)\nend\n\n\n\n\n\n","category":"function"},{"location":"api/#OptimizingIR.LookupTable","page":"API Reference","title":"OptimizingIR.LookupTable","text":"Generic struct for a lookup table that stores an ordered list of distinct elements.\n\nelement is stored in entries vector at index i.\nindex[element] retrieves the index i.\n\nUse addentry! to add items to the table. It the table already has the item, addentry! will return the existing item's index.\n\n\n\n\n\n","category":"type"},{"location":"api/#OptimizingIR.Const","page":"API Reference","title":"OptimizingIR.Const","text":"Constant value to be encoded directly into the IR. The address is the value itself.\n\n\n\n\n\n","category":"type"},{"location":"api/#OptimizingIR.Variable","page":"API Reference","title":"OptimizingIR.Variable","text":"A variable that can be binded to a value. See OptimizingIR.bind!.\n\n\n\n\n\n","category":"type"},{"location":"api/#OptimizingIR.OptimizationRule","page":"API Reference","title":"OptimizingIR.OptimizationRule","text":"Sets which optimizations are allowed to an Op.\n\n\n\n\n\n","category":"type"},{"location":"#OptimizingIR.jl-1","page":"Home","title":"OptimizingIR.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"<blockquote><i> \"Compilers<br> Keep on compilin'<br> Cause it won't be too long\"<br></i> Wonder, S. </blockquote>","category":"page"},{"location":"#","page":"Home","title":"Home","text":"This package provides an Intermediate Representation (IR) that you can use to build Julia functions at runtime.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"In this IR you can define operations with optimization annotations, so that the IR can run optimization passes in order to generate efficient code.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The IR can be either interpreted or compiled to machine code. Each approach has a trade-off:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"interpreting the IR has no compilation step, but results in a slower execution time when running the function;\ncompiling the IR to machine code builds a Julia expression for the function body and","category":"page"},{"location":"#","page":"Home","title":"Home","text":"goes through the Julia's JIT overhead, but the execution time is faster.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Also, interpreting the IR lets the user inspect each step in the calculation. This is useful for implementing auto-generation of documentation on the calculation performed by the function.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"This package is not very useful if you can write your function by hand. It should be useful for you if you ever find yourself programmatically building functions out of Julia Expressions when translating from other high-level languages.","category":"page"},{"location":"#Case-Study-1","page":"Home","title":"Case Study","text":"","category":"section"},{"location":"#Julia's-compilation-steps-1","page":"Home","title":"Julia's compilation steps","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Let's start with a simple Julia function.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"julia_basic_block_test_function(x::Number) = (((-((10.0 * 2.0 + x) / 1.0) + (x + 10.0 * 2.0) + 1.0) * 1.0 / 2.0) + (0.0 * x) + 1.0) * 1.0\njulia_basic_block_test_function(10.0)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Inspecting Julia's lowered IR we can see that %1 and %5 are the same constants, and are not re-used in later instructions.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"julia> @code_lowered julia_basic_block_test_function(10.0)\nCodeInfo(\n1 ─ %1  = 10.0 * 2.0\n│   %2  = %1 + x\n│   %3  = %2 / 1.0\n│   %4  = -%3\n│   %5  = 10.0 * 2.0\n│   %6  = x + %5\n│   %7  = %4 + %6 + 1.0\n│   %8  = %7 * 1.0\n│   %9  = %8 / 2.0\n│   %10 = 0.0 * x\n│   %11 = %9 + %10 + 1.0\n│   %12 = %11 * 1.0\n└──       return %12\n)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The typed IR is better at constant propagation, but stil repeats a few operations.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"julia> @code_typed julia_basic_block_test_function(10.0)\nCodeInfo(\n1 ─ %1  = Base.add_float(20.0, x)::Float64\n│   %2  = Base.div_float(%1, 1.0)::Float64\n│   %3  = Base.neg_float(%2)::Float64\n│   %4  = Base.add_float(x, 20.0)::Float64\n│   %5  = Base.add_float(%3, %4)::Float64\n│   %6  = Base.add_float(%5, 1.0)::Float64\n│   %7  = Base.mul_float(%6, 1.0)::Float64\n│   %8  = Base.div_float(%7, 2.0)::Float64\n│   %9  = Base.mul_float(0.0, x)::Float64\n│   %10 = Base.add_float(%8, %9)::Float64\n│   %11 = Base.add_float(%10, 1.0)::Float64\n│   %12 = Base.mul_float(%11, 1.0)::Float64\n└──       return %12\n) => Float64","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Why is that, given that Julia should generate very efficient code? Well, nothing is wrong really. Julia just doesn't have enough information to optimize instructions in the early phase of the Julia IR.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"When the Julia compiler reaches the LLVM phase, it generates efficient code.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"julia> @code_llvm julia_basic_block_test_function(10.0)\n\n;  @ REPL[1]:1 within `julia_basic_block_test_function'\ndefine double @julia_julia_basic_block_test_function_16035(double) {\ntop:\n; ┌ @ float.jl:395 within `+'\n   %1 = fadd double %0, 2.000000e+01\n; └\n; ┌ @ operators.jl:529 within `+' @ float.jl:395\n   %2 = fsub double %1, %1\n   %3 = fadd double %2, 1.000000e+00\n; └\n; ┌ @ float.jl:401 within `/'\n   %4 = fmul double %3, 5.000000e-01\n; └\n; ┌ @ float.jl:399 within `*'\n   %5 = fmul double %0, 0.000000e+00\n; └\n; ┌ @ operators.jl:529 within `+' @ float.jl:395\n   %6 = fadd double %5, %4\n   %7 = fadd double %6, 1.000000e+00\n; └\n  ret double %7\n}","category":"page"},{"location":"#","page":"Home","title":"Home","text":"So, why bother using another IR?","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Well, if you're programmatically building functions out of Julia Expressions, you may reach a billion nodes on a single Julia Expression instead of a few thousand nodes that should be sufficient if you had optimizations enabled.","category":"page"},{"location":"#Using-OptimizingIR-1","page":"Home","title":"Using OptimizingIR","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"By using OptimizingIR you give the compiler sufficient information to perform early optimization passes as you build the IR.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"import OptimizingIR\nconst OIR = OptimizingIR\n\n# define op-codes with optimization annotations\nconst op_sum = OIR.Op(+, pure=true, commutative=true, hasleftidentity=true, hasrightidentity=true, identity_element=0)\nconst op_sub = OIR.Op(-, pure=true, hasrightidentity=true, identity_element=0)\nconst op_mul = OIR.Op(*, pure=true, commutative=true, hasleftidentity=true, hasrightidentity=true, identity_element=1)\nconst op_div = OIR.Op(/, pure=true, hasrightidentity=true, identity_element=1)\n\nbb = OIR.BasicBlock()\nx = OIR.ImmutableVariable(:x)\nOIR.addinput!(bb, x)\narg1 = OIR.constant(10.0)\narg2 = OIR.constant(2.0)\narg3 = OIR.addinstruction!(bb, OIR.call(op_mul, arg1, arg2))\narg4 = OIR.addinstruction!(bb, OIR.call(op_sum, arg3, x))\narg5 = OIR.constant(1.0)\narg6 = OIR.addinstruction!(bb, OIR.call(op_div, arg4, arg5))\narg7 = OIR.addinstruction!(bb, OIR.call(op_sub, arg6))\narg8 = OIR.addinstruction!(bb, OIR.call(op_sum, x, arg3))\narg9 = OIR.addinstruction!(bb, OIR.call(op_sum, arg8, arg7))\narg10 = OIR.addinstruction!(bb, OIR.call(op_sum, arg9, arg5))\narg11 = OIR.addinstruction!(bb, OIR.call(op_mul, arg10, arg5))\narg12 = OIR.addinstruction!(bb, OIR.call(op_div, arg11, arg2))\narg13 = OIR.constant(0.0)\narg14 = OIR.addinstruction!(bb, OIR.call(op_mul, arg13, x))\narg15 = OIR.addinstruction!(bb, OIR.call(op_sum, arg14, arg12))\narg16 = OIR.constant(1.0)\narg17 = OIR.addinstruction!(bb, OIR.call(op_sum, arg16, arg15))\narg18 = OIR.addinstruction!(bb, OIR.call(op_mul, arg16, arg17))\nvar_output = OIR.MutableVariable(:output)\nOIR.addoutput!(bb, var_output)\nOIR.assign!(bb, var_output, arg18)\n\nprintln(bb)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"From an IR, you can compile it to a function.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"finterpreter = OIR.compile(OIR.BasicBlockInterpreter, bb)\nprintln(\"finterpreter(10.0) = $( finterpreter(10.0) )\")\nfnative = OIR.compile(OIR.Native, bb)\nprintln(\"fnative(10.0) = $( fnative(10.0) )\")","category":"page"}]
}
